# Streaming-ETL-Pipeline-using-Kafka
#### This is the Final-project of ETL and Data Pipelines with Shell, Airflow and Kafka Course - IBM Data Engineering PROFESSIONAL CERTIFICATE on Coursera

The project aims to decongest the national highways by analyzing the road traffic data from different toll plazas. Each highway is operated by a different toll operator with different IT setups that use different file formats. 

As a vehicle passes a toll plaza, the vehicle's data like vehicle_id,vehicle_type,toll_plaza_id, and timestamp are streamed to Kafka.  

The job is to create a data pipeline that collects the streaming data and loads it into a database.

#### The Main Tasks

Task 1: Start Zookeeper 

Task 2: Start Kafka server

Task 3: Create a topic named toll 

Task 4: Download the Toll Traffic Simulator 

Task 5: Configure the Toll Traffic Simulator 

Task 6: Run the Toll Traffic Simulator 

![alt text](https://github.com/aia-elkashef/Streaming-ETL-Pipeline-using-Kafka/blob/main/simulator_output.jpg)


Task 7: Configure streaming_data_reader.py 

Task 8: Run streaming_data_reader.py 

![alt text](https://github.com/aia-elkashef/Streaming-ETL-Pipeline-using-Kafka/blob/main/data_reader_output.jpg)


Task 9: Health check of the streaming data pipeline 

![alt text](https://github.com/aia-elkashef/Streaming-ETL-Pipeline-using-Kafka/blob/main/output_rows.jpg)



